{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import sys\n",
    "import time\n",
    "from csv import writer\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confuse(y_true, y_pred):\n",
    "    return pd.DataFrame(\n",
    "        data = confusion_matrix(y_true, y_pred).T,\n",
    "        columns = ['real false', 'real true'],\n",
    "        index = ['pred false', 'pred true']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evl(model, y_true, y_pred, title):\n",
    "    matrix = confusion_matrix(y_true, y_pred).T\n",
    "    tp = matrix[1, 1]\n",
    "    tn = matrix[0, 0]\n",
    "    fp = matrix[1, 0]\n",
    "    fn = matrix[0, 1]\n",
    "    return pd.DataFrame(\n",
    "        data = {\n",
    "            'accuracy': [np.round((tp + tn) / (tp + tn + fp + fn), 3)],\n",
    "            'sensitivity': [np.round(tp / (tp + fn), 3)],\n",
    "            'specificity': [np.round(tn / (tn + fp), 3)],\n",
    "            'precision': [np.round(tp / (tp + fp), 3)],\n",
    "            'ROC AUC': [np.round(roc_auc_score(y_true, y_pred), 3)],\n",
    "        },\n",
    "        index = [title]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting raw image pixel data\n",
    "When opening an image with the PIL library, the pixel data can be extracted with the `getdata()` method. The images were saved as 32x32 greyscale jpeg images in the `binary_images/img/` folder. Greyscale means that every pixel is described by a single integer between 0 and 255, where 0 is pitch black and 255 is perfect white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('../binary_images/img/img_0_0.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(img.getdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89,\n",
       " 90,\n",
       " 92,\n",
       " 92,\n",
       " 90,\n",
       " 87,\n",
       " 83,\n",
       " 80,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 80,\n",
       " 82,\n",
       " 83,\n",
       " 85,\n",
       " 85,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 83,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 85,\n",
       " 84,\n",
       " 83,\n",
       " 82,\n",
       " 89,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 90,\n",
       " 87,\n",
       " 83,\n",
       " 81,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 82,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 86,\n",
       " 86,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 90,\n",
       " 87,\n",
       " 84,\n",
       " 82,\n",
       " 78,\n",
       " 78,\n",
       " 80,\n",
       " 81,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 87,\n",
       " 86,\n",
       " 85,\n",
       " 84,\n",
       " 85,\n",
       " 87,\n",
       " 88,\n",
       " 90,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 91,\n",
       " 90,\n",
       " 88,\n",
       " 85,\n",
       " 83,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 84,\n",
       " 84,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 90,\n",
       " 88,\n",
       " 86,\n",
       " 85,\n",
       " 81,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 83,\n",
       " 85,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 86,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 90,\n",
       " 89,\n",
       " 87,\n",
       " 87,\n",
       " 82,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 86,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 90,\n",
       " 89,\n",
       " 88,\n",
       " 88,\n",
       " 83,\n",
       " 83,\n",
       " 84,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 89,\n",
       " 87,\n",
       " 85,\n",
       " 83,\n",
       " 82,\n",
       " 82,\n",
       " 84,\n",
       " 85,\n",
       " 92,\n",
       " 91,\n",
       " 91,\n",
       " 90,\n",
       " 90,\n",
       " 89,\n",
       " 89,\n",
       " 88,\n",
       " 83,\n",
       " 84,\n",
       " 84,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 89,\n",
       " 85,\n",
       " 79,\n",
       " 74,\n",
       " 73,\n",
       " 75,\n",
       " 80,\n",
       " 83,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 89,\n",
       " 89,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 88,\n",
       " 90,\n",
       " 90,\n",
       " 87,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 76,\n",
       " 71,\n",
       " 78,\n",
       " 84,\n",
       " 86,\n",
       " 88,\n",
       " 92,\n",
       " 90,\n",
       " 90,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 84,\n",
       " 84,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 87,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 77,\n",
       " 71,\n",
       " 72,\n",
       " 80,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 84,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 88,\n",
       " 87,\n",
       " 86,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 85,\n",
       " 84,\n",
       " 73,\n",
       " 72,\n",
       " 76,\n",
       " 86,\n",
       " 93,\n",
       " 92,\n",
       " 88,\n",
       " 86,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 87,\n",
       " 87,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 87,\n",
       " 87,\n",
       " 84,\n",
       " 79,\n",
       " 75,\n",
       " 70,\n",
       " 71,\n",
       " 75,\n",
       " 81,\n",
       " 85,\n",
       " 83,\n",
       " 79,\n",
       " 75,\n",
       " 89,\n",
       " 89,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 87,\n",
       " 87,\n",
       " 87,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 90,\n",
       " 86,\n",
       " 79,\n",
       " 70,\n",
       " 64,\n",
       " 65,\n",
       " 65,\n",
       " 65,\n",
       " 65,\n",
       " 65,\n",
       " 65,\n",
       " 62,\n",
       " 59,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 87,\n",
       " 87,\n",
       " 87,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 86,\n",
       " 90,\n",
       " 92,\n",
       " 89,\n",
       " 82,\n",
       " 71,\n",
       " 63,\n",
       " 58,\n",
       " 65,\n",
       " 66,\n",
       " 63,\n",
       " 58,\n",
       " 57,\n",
       " 60,\n",
       " 60,\n",
       " 58,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 87,\n",
       " 87,\n",
       " 87,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 88,\n",
       " 85,\n",
       " 89,\n",
       " 91,\n",
       " 86,\n",
       " 74,\n",
       " 64,\n",
       " 60,\n",
       " 60,\n",
       " 65,\n",
       " 68,\n",
       " 66,\n",
       " 61,\n",
       " 61,\n",
       " 67,\n",
       " 71,\n",
       " 70,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 87,\n",
       " 87,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 84,\n",
       " 89,\n",
       " 90,\n",
       " 82,\n",
       " 68,\n",
       " 60,\n",
       " 60,\n",
       " 65,\n",
       " 60,\n",
       " 65,\n",
       " 65,\n",
       " 62,\n",
       " 64,\n",
       " 72,\n",
       " 78,\n",
       " 77,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 90,\n",
       " 89,\n",
       " 87,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 89,\n",
       " 89,\n",
       " 92,\n",
       " 87,\n",
       " 80,\n",
       " 72,\n",
       " 66,\n",
       " 62,\n",
       " 61,\n",
       " 61,\n",
       " 60,\n",
       " 63,\n",
       " 69,\n",
       " 77,\n",
       " 85,\n",
       " 89,\n",
       " 89,\n",
       " 87,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 93,\n",
       " 85,\n",
       " 72,\n",
       " 61,\n",
       " 55,\n",
       " 57,\n",
       " 63,\n",
       " 67,\n",
       " 65,\n",
       " 73,\n",
       " 83,\n",
       " 89,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 93,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 87,\n",
       " 80,\n",
       " 69,\n",
       " 60,\n",
       " 58,\n",
       " 62,\n",
       " 69,\n",
       " 74,\n",
       " 70,\n",
       " 80,\n",
       " 91,\n",
       " 94,\n",
       " 90,\n",
       " 85,\n",
       " 84,\n",
       " 86,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 90,\n",
       " 91,\n",
       " 80,\n",
       " 79,\n",
       " 77,\n",
       " 76,\n",
       " 75,\n",
       " 76,\n",
       " 76,\n",
       " 77,\n",
       " 72,\n",
       " 77,\n",
       " 82,\n",
       " 82,\n",
       " 76,\n",
       " 70,\n",
       " 68,\n",
       " 68,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 88,\n",
       " 88,\n",
       " 89,\n",
       " 89,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 84,\n",
       " 81,\n",
       " 78,\n",
       " 75,\n",
       " 71,\n",
       " 70,\n",
       " 69,\n",
       " 68,\n",
       " 68,\n",
       " 66,\n",
       " 64,\n",
       " 63,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 89,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 90,\n",
       " 90,\n",
       " 89,\n",
       " 89,\n",
       " 91,\n",
       " 89,\n",
       " 85,\n",
       " 80,\n",
       " 77,\n",
       " 75,\n",
       " 74,\n",
       " 74,\n",
       " 73,\n",
       " 70,\n",
       " 68,\n",
       " 69,\n",
       " 73,\n",
       " 76,\n",
       " 77,\n",
       " 76,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 91,\n",
       " 91,\n",
       " 92,\n",
       " 91,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 85,\n",
       " 82,\n",
       " 77,\n",
       " 72,\n",
       " 70,\n",
       " 71,\n",
       " 74,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 85,\n",
       " 87,\n",
       " 89,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 91,\n",
       " 89,\n",
       " 87,\n",
       " 85,\n",
       " 71,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 72,\n",
       " 74,\n",
       " 76,\n",
       " 78,\n",
       " 80,\n",
       " 86,\n",
       " 91,\n",
       " 91,\n",
       " 87,\n",
       " 85,\n",
       " 88,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 90,\n",
       " 89,\n",
       " 88,\n",
       " 86,\n",
       " 86,\n",
       " 76,\n",
       " 76,\n",
       " 76,\n",
       " 77,\n",
       " 79,\n",
       " 81,\n",
       " 84,\n",
       " 86,\n",
       " 89,\n",
       " 88,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 92,\n",
       " 94,\n",
       " 95,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 90,\n",
       " 88,\n",
       " 87,\n",
       " 86,\n",
       " 82,\n",
       " 82,\n",
       " 82,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 85,\n",
       " 90,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 90,\n",
       " 89,\n",
       " 88,\n",
       " 87,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 87,\n",
       " 87,\n",
       " 86,\n",
       " 84,\n",
       " 84,\n",
       " 78,\n",
       " 80,\n",
       " 82,\n",
       " 84,\n",
       " 84,\n",
       " 82,\n",
       " 80,\n",
       " 78,\n",
       " 91,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 93,\n",
       " 93,\n",
       " 91,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 91,\n",
       " 90,\n",
       " 89,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 91,\n",
       " 90,\n",
       " 88,\n",
       " 86,\n",
       " 84,\n",
       " 86,\n",
       " 88,\n",
       " 91,\n",
       " 93,\n",
       " 93,\n",
       " 89,\n",
       " 85,\n",
       " 82,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 93,\n",
       " 93,\n",
       " 93,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 91,\n",
       " 90,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 94,\n",
       " 92,\n",
       " 91,\n",
       " 90,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 94,\n",
       " 90,\n",
       " 84,\n",
       " 79,\n",
       " 75,\n",
       " 90,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 94,\n",
       " 92,\n",
       " 92,\n",
       " 93,\n",
       " 93,\n",
       " 93,\n",
       " 92,\n",
       " 92,\n",
       " 91,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 95,\n",
       " 96,\n",
       " 95,\n",
       " 95,\n",
       " 95,\n",
       " 90,\n",
       " 89,\n",
       " 85,\n",
       " 81,\n",
       " 75,\n",
       " 68,\n",
       " 63,\n",
       " 60,\n",
       " 90,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 94,\n",
       " 92,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 94,\n",
       " 93,\n",
       " 93,\n",
       " 92,\n",
       " 93,\n",
       " 93,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 93,\n",
       " 93,\n",
       " 91,\n",
       " 88,\n",
       " 84,\n",
       " 79,\n",
       " 74,\n",
       " 72,\n",
       " 70,\n",
       " 70,\n",
       " 90,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 94,\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32 * 32 # size of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually label flood and non-flood images.\n",
    "In order to train a model on whether or not an image is flooded, it needs both images of floods and images of non-floods. The images included in the object detection portion of the lab were all of floods, so I added an extra ~400 pictures that I had manually filtered out of my NYT query. Below is the list of manually labeled data, where every number below corresponds to the index of one non-flood image in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../binary_images/data/non_flood_images.txt') as file:\n",
    "    file_contents = file.readlines()\n",
    "\n",
    "non_flood_images =[int(num.strip()) for num in (''.join(file_contents)).split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_flood_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40198237885462557"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "365 / 908"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 145,000 images from data augmentation is about 1 GB worth of memory. During programming I ran into many performance drops because of the large amount of data, in particular with creating DataFrames. The way that worked the fastest was saving the entire data of every image into a single csv file, which is then loaded into a dataframe below. The images are saved to `binary_images/data/binary_img.csv`. Note that even though the data only takes up 1 GB on its own, training the models and some additional overhead push the memory usage up to 2 GB or higher. As a result the code below will likely struggle or fail when run on machines with only 4 GB of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image 0 at time 0 s...\n",
      "Loading image 100 at time 5 s...\n",
      "Loading image 200 at time 9 s...\n",
      "Loading image 300 at time 13 s...\n",
      "Loading image 400 at time 17 s...\n",
      "Loading image 500 at time 21 s...\n",
      "Loading image 600 at time 26 s...\n",
      "Loading image 700 at time 30 s...\n",
      "Loading image 800 at time 34 s...\n",
      "Loading image 900 at time 39 s...\n",
      "Writing line 0 at time 39 s...\n",
      "Writing line 10000 at time 43 s...\n",
      "Writing line 20000 at time 48 s...\n",
      "Writing line 30000 at time 52 s...\n",
      "Writing line 40000 at time 56 s...\n",
      "Writing line 50000 at time 60 s...\n",
      "Writing line 60000 at time 64 s...\n",
      "Writing line 70000 at time 69 s...\n",
      "Writing line 80000 at time 73 s...\n",
      "Writing line 90000 at time 77 s...\n",
      "Writing line 100000 at time 82 s...\n",
      "Writing line 110000 at time 86 s...\n",
      "Writing line 120000 at time 90 s...\n",
      "Writing line 130000 at time 95 s...\n",
      "Writing line 140000 at time 99 s...\n",
      "Done. Took 102 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "label_list = []\n",
    "img_list = []\n",
    "for i in range(0, 908):\n",
    "    if i % 100 == 0:\n",
    "        print(f'Loading image {i} at time {round(time.time() - start_time)} s...')\n",
    "    is_flood = int(i not in non_flood_images)\n",
    "    for j in range(0, 160):\n",
    "        with Image.open(f'../binary_images/img/img_{i}_{j}.jpg') as image:\n",
    "            img_list.append(np.array(image.getdata(), np.uint8))\n",
    "            label_list.append(is_flood)\n",
    "\n",
    "with open('../binary_images/data/binary_img.csv', 'w') as file:\n",
    "    csv_writer = writer(file)\n",
    "    \n",
    "    for i, image in enumerate(img_list):\n",
    "        if i % 10000 == 0:\n",
    "            print(f'Writing line {i} at time {round(time.time() - start_time)} s...')\n",
    "        csv_writer.writerow(list(image) + [label_list[i]])\n",
    "\n",
    "print(f'Done. Took {round(time.time() - start_time)} seconds.')\n",
    "del label_list\n",
    "del img_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the image data into a dataframe\n",
    "Now that all the images are saved into one file, Pandas can take over and load it with great speed. This method has some notable drawbacks. A computer is limited by its RAM in loading the size of this file, meaning the file should never realistically go above 4-6 GB. Not to mention that this will more than double the size of the image data on your hard drive, since jpg images are compressed while the csv result will not be. This solution only works for datasets on the order of this size or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.9 s, sys: 1.55 s, total: 13.5 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('../binary_images/data/binary_img.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.19129616"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(df) / 1_000_000_000 # size of dataframe in gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145280, 1025)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # (number of images, pixels per image + label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>87</td>\n",
       "      <td>83</td>\n",
       "      <td>80</td>\n",
       "      <td>76</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>75</td>\n",
       "      <td>72</td>\n",
       "      <td>69</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "      <td>102</td>\n",
       "      <td>105</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "      <td>91</td>\n",
       "      <td>94</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>84</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>81</td>\n",
       "      <td>76</td>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>90</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>88</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "      <td>86</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>47</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "      <td>84</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>83</td>\n",
       "      <td>83</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145275</th>\n",
       "      <td>164</td>\n",
       "      <td>175</td>\n",
       "      <td>146</td>\n",
       "      <td>189</td>\n",
       "      <td>240</td>\n",
       "      <td>214</td>\n",
       "      <td>142</td>\n",
       "      <td>166</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>176</td>\n",
       "      <td>133</td>\n",
       "      <td>87</td>\n",
       "      <td>146</td>\n",
       "      <td>250</td>\n",
       "      <td>246</td>\n",
       "      <td>255</td>\n",
       "      <td>236</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145276</th>\n",
       "      <td>227</td>\n",
       "      <td>227</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>224</td>\n",
       "      <td>224</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>85</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>96</td>\n",
       "      <td>108</td>\n",
       "      <td>127</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145277</th>\n",
       "      <td>107</td>\n",
       "      <td>99</td>\n",
       "      <td>201</td>\n",
       "      <td>149</td>\n",
       "      <td>52</td>\n",
       "      <td>67</td>\n",
       "      <td>42</td>\n",
       "      <td>152</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>171</td>\n",
       "      <td>168</td>\n",
       "      <td>165</td>\n",
       "      <td>164</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145278</th>\n",
       "      <td>195</td>\n",
       "      <td>253</td>\n",
       "      <td>252</td>\n",
       "      <td>255</td>\n",
       "      <td>235</td>\n",
       "      <td>227</td>\n",
       "      <td>216</td>\n",
       "      <td>228</td>\n",
       "      <td>132</td>\n",
       "      <td>108</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145279</th>\n",
       "      <td>246</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>250</td>\n",
       "      <td>251</td>\n",
       "      <td>255</td>\n",
       "      <td>197</td>\n",
       "      <td>189</td>\n",
       "      <td>184</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>153</td>\n",
       "      <td>146</td>\n",
       "      <td>153</td>\n",
       "      <td>150</td>\n",
       "      <td>141</td>\n",
       "      <td>140</td>\n",
       "      <td>150</td>\n",
       "      <td>154</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145280 rows × 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9     ...  1015  \\\n",
       "0         89    90    92    92    90    87    83    80    76    77  ...    88   \n",
       "1         88    88    88    88    88    88    88    88    90    89  ...    95   \n",
       "2         93    91    89    90    93    95    93    91    94    93  ...   113   \n",
       "3         89    92    90    85    84    88    93    93    86    85  ...    52   \n",
       "4         84    84    84    84    84    84    84    84    83    83  ...    70   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "145275   164   175   146   189   240   214   142   166   151   152  ...   176   \n",
       "145276   227   227   226   226   226   225   225   225   224   224  ...    75   \n",
       "145277   107    99   201   149    52    67    42   152   100    45  ...   168   \n",
       "145278   195   253   252   255   235   227   216   228   132   108  ...    18   \n",
       "145279   246   255   255   250   251   255   197   189   184   202  ...   153   \n",
       "\n",
       "        1016  1017  1018  1019  1020  1021  1022  1023  1024  \n",
       "0         75    72    69    66    65    67    71    73     1  \n",
       "1         95   102   102    94    94   102   105   101     1  \n",
       "2         84    65    70    81    76    79    82    67     1  \n",
       "3         47    66    82    83    82    85    84    79     1  \n",
       "4         82    86    87    84    77    71    65    61     1  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "145275   133    87   146   250   246   255   236   189     0  \n",
       "145276    85    77    83    93    96   108   127   138     0  \n",
       "145277   172   173   173   171   168   165   164   165     0  \n",
       "145278    21    23    25    24    23    23    26    28     0  \n",
       "145279   146   153   150   141   140   150   154   150     0  \n",
       "\n",
       "[145280 rows x 1025 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # column 1024 is the label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5980176211453745"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class balance\n",
    "df[1024].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeyle/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.6066905286343612\n",
      "test 0.5972191629955947\n",
      "CPU times: user 53.3 s, sys: 928 ms, total: 54.2 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[1024]), df[1024], test_size = 0.25, random_state = 2, stratify = df[1024])\n",
    "del df\n",
    "\n",
    "lr = LogisticRegression(max_iter = 100)\n",
    "lr.fit(X_train, y_train)\n",
    "print('train', lr.score(X_train, y_train))\n",
    "print('test', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model performs no better than the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5980176211453745"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real false</th>\n",
       "      <th>real true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred false</th>\n",
       "      <td>2681</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred true</th>\n",
       "      <td>11919</td>\n",
       "      <td>19010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            real false  real true\n",
       "pred false        2681       2710\n",
       "pred true        11919      19010"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    data = confusion_matrix(y_test, lr.predict(X_test)).T,\n",
    "    columns = ['real false', 'real true'],\n",
    "    index = ['pred false', 'pred true']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeyle/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/svm/_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.4491831864904552\n",
      "test 0.44812775330396476\n",
      "CPU times: user 9min 48s, sys: 619 ms, total: 9min 48s\n",
      "Wall time: 9min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[1024]), df[1024], test_size = 0.25, random_state = 2)\n",
    "del df\n",
    "\n",
    "svc = SVC(kernel = 'rbf', max_iter = 1000)\n",
    "svc.fit(X_train, y_train)\n",
    "print('train', svc.score(X_train, y_train))\n",
    "print('test', svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An SVM classifier with RBF kernel performs considerably worse than the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.9971732745961821\n",
      "test 0.7032764317180616\n",
      "CPU times: user 1h 13min 9s, sys: 3.11 s, total: 1h 13min 12s\n",
      "Wall time: 10min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[1024]), df[1024], test_size = 0.25, random_state = 2)\n",
    "del df\n",
    "\n",
    "forest = RandomForestClassifier(\n",
    "    n_estimators = 1024,\n",
    "    max_depth = 32,\n",
    "    n_jobs = 7\n",
    ")\n",
    "forest.fit(X_train, y_train)\n",
    "print('train', forest.score(X_train, y_train))\n",
    "print('test', forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real false</th>\n",
       "      <th>real true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred false</th>\n",
       "      <td>4487</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred true</th>\n",
       "      <td>10086</td>\n",
       "      <td>21056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            real false  real true\n",
       "pred false        4487        691\n",
       "pred true        10086      21056"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse(y_test, forest.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Forest</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy  sensitivity  specificity  precision  ROC AUC\n",
       "Forest     0.703        0.968        0.308      0.676    0.638"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl(forest, y_test, forest.predict(X_test), 'Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model performs quite well. Stumps (max_depth ~ 1-4) perform poorly, while going much deeper than this results in perfect overfitting on the train dataset. The overfitting can be managed by a huge number of estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/neural_networks_supervised.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeyle/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.8320851688693098\n",
      "test 0.7987885462555067\n",
      "CPU times: user 57min 37s, sys: 55.5 s, total: 58min 33s\n",
      "Wall time: 15min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('../binary_images/data/binary_img.csv', header=None)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=[1024]), \n",
    "    df[1024], \n",
    "    test_size = 0.25, \n",
    "    random_state = 2\n",
    ")\n",
    "del df # going above your system's allocated memory will instantly crash the ipynb kernel, so just reload and delete the csv every time\n",
    "\n",
    "ss = StandardScaler(copy = False, with_mean = 0, with_std = 1)\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes = (256, 64, 16, 4),\n",
    "    activation = 'logistic',\n",
    "    solver = 'adam',\n",
    "    random_state = 2,\n",
    ")    \n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "print('train', mlp.score(X_train, y_train))\n",
    "print('test', mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real false</th>\n",
       "      <th>real true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred false</th>\n",
       "      <td>11946</td>\n",
       "      <td>4681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred true</th>\n",
       "      <td>2627</td>\n",
       "      <td>17066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            real false  real true\n",
       "pred false       11946       4681\n",
       "pred true         2627      17066"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse(y_test, mlp.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  sensitivity  specificity  precision  ROC AUC\n",
       "MLP     0.799        0.785         0.82      0.867    0.802"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl(mlp, y_test, mlp.predict(X_test), 'MLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple MLP NN performs extraordinarily well at the cost of a ridiculous training time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More neural network models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(layers):\n",
    "    start_time = time.time()\n",
    "    df = pd.read_csv('../binary_images/data/binary_img.csv', header=None)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        df.drop(columns=[1024]), \n",
    "        df[1024], \n",
    "        test_size = 0.25, \n",
    "        random_state = 2\n",
    "    )\n",
    "    del df # going above your system's allocated memory will instantly crash the ipynb kernel, so just reload and delete the csv every time\n",
    "\n",
    "    ss = StandardScaler(copy = False, with_mean = 0, with_std = 1)\n",
    "    X_train = ss.fit_transform(X_train)\n",
    "    X_test = ss.transform(X_test)\n",
    "\n",
    "    mlp = MLPClassifier(\n",
    "        hidden_layer_sizes = layers, \n",
    "        activation = 'logistic',\n",
    "        solver = 'adam',\n",
    "        random_state = 2,\n",
    "    )    \n",
    "\n",
    "    mlp.fit(X_train, y_train)\n",
    "    print('train', mlp.score(X_train, y_train))\n",
    "    print('test', mlp.score(X_test, y_test))\n",
    "    print(f'Took {round(time.time() - start_time)} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeyle/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.7468704111600587\n",
      "test 0.7112334801762115\n"
     ]
    }
   ],
   "source": [
    "nn_model((16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_count(layers):\n",
    "    print('n nodes', sum(layers))\n",
    "    print('n connections', sum([layers[i] * layers[i+1] for i in range(len(layers)-1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n nodes 84\n",
      "n connections 1088\n"
     ]
    }
   ],
   "source": [
    "nn_count((64, 16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeyle/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.8230543318649045\n",
      "test 0.7816629955947136\n",
      "Took 255 seconds.\n"
     ]
    }
   ],
   "source": [
    "nn_model((64, 16, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n nodes 56\n",
      "n connections 640\n"
     ]
    }
   ],
   "source": [
    "nn_count((32, 16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeyle/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.751642804698972\n",
      "test 0.7254955947136564\n",
      "Took 177 seconds.\n"
     ]
    }
   ],
   "source": [
    "nn_model((32, 16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n nodes 136\n",
      "n connections 1024\n"
     ]
    }
   ],
   "source": [
    "nn_count((128, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeyle/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.846264684287812\n",
      "test 0.8210352422907489\n",
      "Took 442 seconds.\n"
     ]
    }
   ],
   "source": [
    "nn_model((128, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n nodes 168\n",
      "n connections 4352\n"
     ]
    }
   ],
   "source": [
    "nn_count((128, 32, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeyle/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.8215859030837004\n",
      "test 0.7878579295154186\n",
      "Took 457 seconds.\n"
     ]
    }
   ],
   "source": [
    "nn_model((128, 32, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n nodes 224\n",
      "n connections 12288\n"
     ]
    }
   ],
   "source": [
    "nn_count((64, 128, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeyle/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.8028267254038179\n",
      "test 0.7777533039647577\n",
      "Took 337 seconds.\n"
     ]
    }
   ],
   "source": [
    "nn_model((64, 128, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n nodes 256\n",
      "n connections 12288\n"
     ]
    }
   ],
   "source": [
    "nn_count((64, 64, 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeyle/anaconda3/envs/dsi/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.793906020558003\n",
      "test 0.7664922907488987\n",
      "Took 346 seconds.\n"
     ]
    }
   ],
   "source": [
    "nn_model((64, 64, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.8584342878120411\n",
      "test 0.8239262114537445\n",
      "CPU times: user 24min 21s, sys: 30.6 s, total: 24min 52s\n",
      "Wall time: 6min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('../binary_images/data/binary_img.csv', header=None)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(columns=[1024]), \n",
    "    df[1024], \n",
    "    test_size = 0.25, \n",
    "    random_state = 2\n",
    ")\n",
    "del df # going above your system's allocated memory will instantly crash the ipynb kernel, so just reload and delete the csv every time\n",
    "\n",
    "ss = StandardScaler(copy = False, with_mean = 0, with_std = 1)\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.transform(X_test)\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes = (128, 16), \n",
    "    activation = 'logistic',\n",
    "    solver = 'adam',\n",
    "    random_state = 2,\n",
    "    max_iter = 500\n",
    ")    \n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "print('train', mlp.score(X_train, y_train))\n",
    "print('test', mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real false</th>\n",
       "      <th>real true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pred false</th>\n",
       "      <td>12418</td>\n",
       "      <td>4240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred true</th>\n",
       "      <td>2155</td>\n",
       "      <td>17507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            real false  real true\n",
       "pred false       12418       4240\n",
       "pred true         2155      17507"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confuse(y_test, mlp.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>precision</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     accuracy  sensitivity  specificity  precision  ROC AUC\n",
       "MLP     0.824        0.805        0.852       0.89    0.829"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evl(mlp, y_test, mlp.predict(X_test), 'MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path = '../binary_images/flood_image_classifier_mlp_128_16.sav'\n",
    "pickle.dump(mlp, open(final_model_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
